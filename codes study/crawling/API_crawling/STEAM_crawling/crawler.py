# crawler.py
import steamreviews
import requests
import json
import sys
import os
from bs4 import BeautifulSoup # HTML íŒŒì‹±ì„ ìœ„í•´ ìƒˆë¡œ ì¶”ê°€

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
try:
    import requests
except ImportError:
    print("requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install requestsë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ==========================================
# 1ë‹¨ê³„: ê²Œì„ ì´ë¦„ìœ¼ë¡œ App ID ê²€ìƒ‰

def get_app_id_by_name(game_name):
    """Steam ìƒì  ê²€ìƒ‰ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ê²Œì„ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” App IDë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    
    search_url = f"https://store.steampowered.com/search/?term={game_name}&supportedlang=koreana"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    print(f"ğŸ”„ Steam ìƒì  ê²€ìƒ‰ ì¤‘: '{game_name}'")
    
    try:
        response = requests.get(search_url, headers=headers, timeout=15)
        response.raise_for_status() 
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ í–‰ (ê°€ì¥ ì •í™•í•œ ê²°ê³¼ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
        first_result = soup.find('a', class_='search_result_row')
        
        if first_result:
            # App IDëŠ” HTML ìš”ì†Œì˜ data-ds-appid ì†ì„±ì— í¬í•¨ë˜ì–´ ìˆìŒ
            app_id = first_result.get('data-ds-appid')
            # ê²Œì„ ì œëª©ë„ í•¨ê»˜ ê°€ì ¸ì™€ì„œ í™•ì¸
            title_tag = first_result.find('span', class_='title')
            game_title = title_tag.text if title_tag else "ì œëª© ë¯¸ìƒ"
            
            if app_id:
                print(f"âœ… App ID ë°œê²¬: {app_id} ({game_title})")
                return int(app_id)
        
        print(f"âŒ '{game_name}'ì— í•´ë‹¹í•˜ëŠ” ê²Œì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Steam ê²€ìƒ‰ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ==========================================
# 2ë‹¨ê³„: App IDë¡œ ë¦¬ë·° ìˆ˜ì§‘

def get_game_reviews(app_id, limit=50):
    """
    íŠ¹ì • ê²Œì„(app_id)ì˜ í•œêµ­ì–´ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. steamreviewsê°€ Paginationì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    request_params = dict(
        language='koreana', 
        filter='recent',    # ìµœì‹ ìˆœ
        num_per_page=100    # í•œ ë²ˆ ìš”ì²­ì— ê°€ì ¸ì˜¬ ê°œìˆ˜
    )
    
    # steamreviews ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    review_dict, _ = steamreviews.download_reviews_for_app_id(
        app_id, 
        chosen_request_params=request_params
    )
    
    reviews_data = []
    if 'reviews' in review_dict:
        # ë¦¬ë·° IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìˆ˜ì§‘ ìˆœì„œë¥¼ ì•ˆì •í™”
        sorted_reviews = sorted(review_dict['reviews'].items(), key=lambda x: x[0], reverse=True) 
        
        count = 0
        for review_id, review in sorted_reviews:
            if count >= limit: break
            
            # ìš”ì²­í•˜ì‹  ëª¨ë“  í•„ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì €ì¥
            reviews_data.append({
                'review_id': review_id,
                'author_id': review['author']['steamid'],
                'playtime_forever': review['author']['playtime_forever'], # ì´ í”Œë ˆì´ ì‹œê°„(ë¶„)
                'review_text': review['review'],
                'voted_up': review['voted_up'] # ì¶”ì²œ/ë¹„ì¶”ì²œ ì—¬ë¶€ (True/False)
            })
            count += 1
            
    return reviews_data

# ==========================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

def main_crawler():
    game_name = input("ğŸ” ê²€ìƒ‰í•  ê²Œì„ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    try:
        limit = int(input("ğŸ”¢ ìˆ˜ì§‘í•  ë¦¬ë·° ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 200): "))
        if limit < 10: raise ValueError
    except ValueError:
        print("ê²½ê³ : ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ 100ê°œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        limit = 100

    # 1. Robust Name to ID Lookup
    app_id = get_app_id_by_name(game_name)
    if not app_id:
        print("í¬ë¡¤ë§ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 2. Review Crawling
    print(f"\n'{game_name}' ({app_id})ì˜ ë¦¬ë·° {limit}ê°œ ìˆ˜ì§‘ ì‹œì‘...")
    reviews_data = get_game_reviews(app_id, limit)
    
    # 3. Save Data
    if reviews_data:
        data_dir = "dataSet"
        try:
            os.makedirs(data_dir, exist_ok=True)
            print(f"ğŸ“‚ ë””ë ‰í† ë¦¬ '{data_dir}' ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return # ì‹¤íŒ¨ ì‹œ ì €ì¥ ì¤‘ë‹¨
        
        safe_game_name = game_name.replace(' ', '_')
        output_filename = os.path.join(data_dir, f"reviews_{app_id}_{limit}_{safe_game_name}.json")
        
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(reviews_data, f, ensure_ascii=False, indent=4)
            
        print(f"\n! í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(reviews_data)}ê°œ ë¦¬ë·° ìˆ˜ì§‘.")
        print(f"ğŸ“‚ ë°ì´í„°ê°€ '{output_filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return reviews_data
    else:
        print("âš ï¸ ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ì‹¤íŒ¨ ë˜ëŠ” ë¦¬ë·°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return []

if __name__ == "__main__":
    main_crawler()
    